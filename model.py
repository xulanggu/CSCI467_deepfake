import os
import pandas as pd
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models

# --- Custom Dataset using the CSV generated by parse.py ---

class DeepfakePaintingDataset(Dataset):
    def __init__(self, data_frame, transform=None):
        """
        Args:
            data_frame (pd.DataFrame): DataFrame containing image paths, labels, and split info.
            transform (callable, optional): Optional transform to be applied on an image.
        """
        self.data = data_frame
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # Get the row for this index
        row = self.data.iloc[idx]
        img_path = row['path']
        label_str = row['label']
        # Convert label to integer: 1 for real, 0 for fake (adjust as needed)
        label = 1 if label_str.lower() == 'real' else 0

        # Load the image
        image = Image.open(img_path).convert("RGB")
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

# --- Data Transforms ---
# We choose a size that works for both ResNet18 (224x224) and InceptionV3 (299x299).
# For simplicity, we resize to 299x299 (Inception's native size).
transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Standard ImageNet normalization
                         std=[0.229, 0.224, 0.225])
])

# --- Create Dataset and DataLoader ---


# Load the full CSV into a DataFrame
df = pd.read_csv("deepfake_dataset.csv")

# Create separate DataFrames for training and testing
train_df = df[df['split'].str.lower() == 'train']
test_df = df[df['split'].str.lower() == 'test']

# Optionally, print sizes for debugging
print("Train set size:", len(train_df))
print("Test set size:", len(test_df))

# Create the datasets
train_dataset = DeepfakePaintingDataset(train_df, transform=transform)
test_dataset = DeepfakePaintingDataset(test_df, transform=transform)

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)

# --- Combined Model Definition ---

# Custom module to extract features from InceptionV3
class InceptionFeatures(nn.Module):
    def __init__(self, pretrained=True):
        super(InceptionFeatures, self).__init__()
        # Load InceptionV3 with aux_logits disabled
        inception = models.inception_v3(pretrained=pretrained, aux_logits=True)
        # InceptionV3 children structure (simplified):
        # [Conv2d_1a_3x3, Conv2d_2a_3x3, Conv2d_2b_3x3, Mixed_5b, Mixed_5c, Mixed_5d,
        #  Mixed_6a, Mixed_6b, Mixed_6c, Mixed_6d, Mixed_6e, Mixed_7a, Mixed_7b, Mixed_7c,
        #  AdaptiveAvgPool2d, Dropout, fc]
        # We want the features from the AdaptiveAvgPool2d layer.
        # We can create a Sequential container up to (but not including) Dropout.
        layers = list(inception.children())[:-2]  # Exclude Dropout and fc
        self.features = nn.Sequential(*layers)
        
    def forward(self, x):
        # x is expected to have shape [batch, 3, 299, 299]
        x = self.features(x)  # Expected shape: [batch, 2048, 1, 1]
        return x
    

class CombinedModel(nn.Module):
    def __init__(self, num_classes=2):
        super(CombinedModel, self).__init__()
        # Load pretrained ResNet18 and remove its final fc layer
        resnet = models.resnet18(pretrained=True)
        self.resnet = nn.Sequential(*list(resnet.children())[:-1])  # [batch, 512, 1, 1]
        
        # Use our custom InceptionFeatures module
        self.inception = InceptionFeatures(pretrained=True)
        
        # Fully connected layer: concatenated features from ResNet (512) and Inception (2048)
        self.fc = nn.Linear(512 + 2048, num_classes)
        
    def forward(self, x):
        # Forward pass through ResNet18 branch
        resnet_feat = self.resnet(x)  # shape: [batch, 512, 1, 1]
        resnet_feat = resnet_feat.view(resnet_feat.size(0), -1)  # shape: [batch, 512]
        
        # Forward pass through Inception branch
        inception_feat = self.inception(x)  # shape: [batch, 2048, 1, 1]
        inception_feat = inception_feat.view(inception_feat.size(0), -1)  # shape: [batch, 2048]
        
        # Concatenate features from both branches
        fused_features = torch.cat((resnet_feat, inception_feat), dim=1)  # shape: [batch, 2560]
        
        # Classification
        output = self.fc(fused_features)  # shape: [batch, num_classes]
        return output
    
    def evaluate_model(model, dataloader, device):
        model.eval()  # Set model to evaluation mode
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in dataloader:
                images = images.to(device)
                labels = labels.to(device)
                outputs = model(images)
                # For a classification task, the predicted class is the one with highest logit
                _, predicted = torch.max(outputs, dim=1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        accuracy = correct / total if total > 0 else 0
        print(f"Model Accuracy: {accuracy * 100:.2f}%")
        return accuracy

# --- Example Training Loop ---
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CombinedModel(num_classes=2).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)
    
    num_epochs = 20
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * images.size(0)
        
        epoch_loss = running_loss / len(train_dataset)
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}")
    # For example:
    
    model.evaluate_model(model, test_loader, device)

